{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d601dbd6",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94481535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ena sales on hpl</td>\n",
       "      <td>just to update you on this project ' s status ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98 - 6736 &amp; 98 - 9638 for 1997 ( ua 4 issues )</td>\n",
       "      <td>the above referenced meters need to be placed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpl nominations for december 28 , 1999</td>\n",
       "      <td>( see attached file : hpll 228 . xls )\\n- hpll...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revised nom - kcs resources</td>\n",
       "      <td>daren ,\\nit ' s in .\\nbob\\n- - - - - - - - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new production - sitara deals needed</td>\n",
       "      <td>daren ,\\nfyi .\\nbob\\n- - - - - - - - - - - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    email_subject  \\\n",
       "0                                ena sales on hpl   \n",
       "1  98 - 6736 & 98 - 9638 for 1997 ( ua 4 issues )   \n",
       "2          hpl nominations for december 28 , 1999   \n",
       "3                     revised nom - kcs resources   \n",
       "4            new production - sitara deals needed   \n",
       "\n",
       "                                          email_body  is_spam  \n",
       "0  just to update you on this project ' s status ...        0  \n",
       "1  the above referenced meters need to be placed ...        0  \n",
       "2  ( see attached file : hpll 228 . xls )\\n- hpll...        0  \n",
       "3  daren ,\\nit ' s in .\\nbob\\n- - - - - - - - - -...        0  \n",
       "4  daren ,\\nfyi .\\nbob\\n- - - - - - - - - - - - -...        0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re  # Regular expressions\n",
    "import nltk  # Natural Language Toolkit\n",
    "import os  # Operating system utilities (for file paths)\n",
    "from bs4 import BeautifulSoup  # For parsing HTML\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Define the path to the dataset\n",
    "file_dir = \"../DS/enron.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(f\"{file_dir}\")\n",
    "\n",
    "# Display the first 5 rows to understand the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c909e",
   "metadata": {},
   "source": [
    "## Part 1: Basic Text Preprocessing\n",
    "\n",
    "- Only keep colums for the email's body text and the label\n",
    "- Drop rows with duplicated or missing values\n",
    "- Clean email body text by \n",
    "    - Extracting plain text\n",
    "    - Normalizing whitespace\n",
    "    - Removing emails, URLs, and punctuations\n",
    "    - Lowercasing words and stripping leading/trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2301836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just to update you on this project ' s status ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the above referenced meters need to be placed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( see attached file : hpll 228 . xls )\\n- hpll...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daren ,\\nit ' s in .\\nbob\\n- - - - - - - - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daren ,\\nfyi .\\nbob\\n- - - - - - - - - - - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "0  just to update you on this project ' s status ...      0\n",
       "1  the above referenced meters need to be placed ...      0\n",
       "2  ( see attached file : hpll 228 . xls )\\n- hpll...      0\n",
       "3  daren ,\\nit ' s in .\\nbob\\n- - - - - - - - - -...      0\n",
       "4  daren ,\\nfyi .\\nbob\\n- - - - - - - - - - - - -...      0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If changing dataset, check which column has the email body \n",
    "# and and which column has label to keep them\n",
    "\n",
    "# Keep only the 'body' (email text) and 'label' (spam/not spam)\n",
    "df = df[['email_body', 'is_spam']]\n",
    "\n",
    "# Rename columns to body and label\n",
    "df.columns = ['body', 'label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c3525",
   "metadata": {},
   "source": [
    "### Data Integrity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64476e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after dropna():\n",
      "body     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove rows with missing values (NaN)\n",
    "df = df.dropna()\n",
    "print(\"Missing values after dropna():\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Remove rows with duplicated email bodies\n",
    "df = df.drop_duplicates(subset=['body'])\n",
    "print(f\"\\nRemaining duplicates: {df.duplicated(subset=['body']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7110c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after basic cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_email_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>just to update you on this project   s status ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the above referenced meters need to be placed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>see attached file   hpll       xls     hpll   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>daren   it   s in   bob                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>daren   fyi   bob                             ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                 cleaned_email_body\n",
       "0      0  just to update you on this project   s status ...\n",
       "1      0  the above referenced meters need to be placed ...\n",
       "2      0  see attached file   hpll       xls     hpll   ...\n",
       "3      0  daren   it   s in   bob                       ...\n",
       "4      0  daren   fyi   bob                             ..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_email_body(html_text):\n",
    "    \"\"\"\n",
    "    Cleans raw email text by:\n",
    "    1. Parsing HTML and extracting plain text.\n",
    "    2. Normalizing whitespace (newlines, tabs, etc.).\n",
    "    3. Removing URLs, email addresses, and all non-alphabetic characters.\n",
    "    4. Lowercasing and stripping final whitespace.\n",
    "    \"\"\"\n",
    "    # 1. Parse HTML and extract plain text\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "    except:\n",
    "        # Handle cases where the body might not be HTML (e.g., just plain text)\n",
    "        # Ensure the input is treated as a string\n",
    "        text = str(html_text)\n",
    "\n",
    "    # 2. Normalize whitespace (replace multiple spaces, newlines, tabs with a single space)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # 3. Remove noise: URLs, emails, and punctuation\n",
    "    text = re.sub(r'http\\S+', ' ', text)      # Replace URLs with a space\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)     # Replace emails with a space\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text) # Replace non-letters/non-spaces with a space\n",
    "\n",
    "    # 4. Final cleanup: lowercase and strip leading/trailing spaces\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'body' column\n",
    "df[\"cleaned_email_body\"] = df[\"body\"].apply(clean_email_body)\n",
    "\n",
    "# Drop the original, raw 'body' column as it's no longer needed\n",
    "df = df.drop(columns=\"body\")\n",
    "\n",
    "print(\"\\nDataFrame after basic cleaning:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d7502",
   "metadata": {},
   "source": [
    "## Part 2: NLP Processing\n",
    "\n",
    "- Downloaded the necessary NLTK packages (punkt, stopwords, wordnet).\n",
    "- Initialized the `WordNetLemmatizer` and created a set of English `stopwords` for fast lookup.\n",
    "- Defined a function (`preprocess_text_2`) that:\n",
    "    - Tokenized the clean text (split it into a list of words).\n",
    "    - Looped through the list and kept only words that were not in the stopword list.\n",
    "    - Lemmatized each of those remaining words.\n",
    "    - Returned `None` if the text became empty (e.g., it only contained stopwords).\n",
    "    - Joined the final list of processed words back into a single string.\n",
    "- Applied this function to the `cleaned_email_body` column.\n",
    "- Stored the output in a new `final_text` column.\n",
    "- Dropped the intermediate `cleaned_email_body` column.\n",
    "- Dropped any rows that was null from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd291d10",
   "metadata": {},
   "source": [
    "### Download NLTK Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25e021be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These only need to be downloaded once.\n",
    "nltk.download('punkt')      # For the tokenizer\n",
    "nltk.download('punkt_tab')  # Additional tokenizer resource\n",
    "nltk.download('stopwords')  # For the list of stopwords\n",
    "nltk.download('wordnet')    # For the lemmatizer\n",
    "nltk.download('omw-1.4')    # Additional lemmatizer resource\n",
    "nltk.download('words')      # For English vocabulary (less common, but good to have)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d713f67",
   "metadata": {},
   "source": [
    "### Initialize NLP Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae616991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopwords loaded: 198\n",
      "Tokenizer test: ['hello', 'world', '!']\n",
      "\n",
      "Missing values per column after NLP processing:\n",
      "label         0\n",
      "final_text    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>update project status based new report scott m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>referenced meter need placed k please note inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>see attached file hpll xl hpll xl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>daren bob forwarded robert cotten hou ect pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>daren fyi bob forwarded robert cotten hou ect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         final_text\n",
       "0      0  update project status based new report scott m...\n",
       "1      0  referenced meter need placed k please note inf...\n",
       "2      0                  see attached file hpll xl hpll xl\n",
       "3      0  daren bob forwarded robert cotten hou ect pm e...\n",
       "4      0  daren fyi bob forwarded robert cotten hou ect ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load stopwords into a set for faster lookup\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(f\"\\nStopwords loaded: {len(stop_words)}\")\n",
    "print(f\"Tokenizer test: {word_tokenize('hello world!')}\")\n",
    "\n",
    "def preprocess_text_2(text, min_words=1):\n",
    "    \"\"\"\n",
    "    Applies tokenization, stopword removal, and lemmatization.\n",
    "    \"\"\"\n",
    "    # 1. Tokenize: Split text into a list of words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    processed_tokens = []\n",
    "    for word in tokens:\n",
    "        # 2. Filter: Remove stopwords and keep only alphabetic words\n",
    "        if word not in stop_words:\n",
    "            # 3. Lemmatize: Reduce word to its root form\n",
    "            processed_tokens.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    # 4. Optional: Skip texts that become empty after processing\n",
    "    # (e.g., an email that only contained stopwords)\n",
    "    if len(processed_tokens) < min_words:\n",
    "        return None # This will be dropped as NaN later\n",
    "\n",
    "    # 5. Re-join the processed tokens into a single string\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# Apply the advanced NLP function\n",
    "df['final_text'] = df['cleaned_email_body'].apply(preprocess_text_2)\n",
    "\n",
    "# Drop the intermediate 'cleaned_email_body' column\n",
    "df = df.drop(columns=\"cleaned_email_body\")\n",
    "\n",
    "# Drop any rows that became empty (NaN) during the NLP step\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"\\nMissing values per column after NLP processing:\")\n",
    "print(df.isna().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417e2ff",
   "metadata": {},
   "source": [
    "### DataFrame Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08d05d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final formatted DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_text</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>update project status based new report scott m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>referenced meter need placed k please note inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>see attached file hpll xl hpll xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daren bob forwarded robert cotten hou ect pm e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daren fyi bob forwarded robert cotten hou ect ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          final_text  is_spam\n",
       "0  update project status based new report scott m...        0\n",
       "1  referenced meter need placed k please note inf...        0\n",
       "2                  see attached file hpll xl hpll xl        0\n",
       "3  daren bob forwarded robert cotten hou ect pm e...        0\n",
       "4  daren fyi bob forwarded robert cotten hou ect ...        0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename 'label' to 'is_spam' for better readability\n",
    "df.rename(columns={'label': 'is_spam'}, inplace=True)\n",
    "\n",
    "# Reorder columns: feature (X) first, target (y) second\n",
    "df = df[['final_text', 'is_spam']]\n",
    "\n",
    "# Reset the DataFrame index after dropping rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nFinal formatted DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2462ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File Saving Utility ---\n",
    "\n",
    "def get_filename_without_ext(file_dir):\n",
    "    \"\"\"\n",
    "    Gets the filename (e.g., \"Ling\") without its extension\n",
    "    from a given path (e.g., \"../DS/Ling.csv\").\n",
    "    \"\"\"\n",
    "    # 1. Get the full filename (e.g., \"Ling.csv\")\n",
    "    filename = os.path.basename(file_dir)\n",
    "    # 2. Split the filename from its extension and return just the name\n",
    "    filename_without_ext = os.path.splitext(filename)[0]\n",
    "    return filename_without_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b9d386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully cleaned and saved data to: ../cleaned_DS/enron_cleaned.csv\n",
      "Total processed emails: 29754\n"
     ]
    }
   ],
   "source": [
    "# --- Save Cleaned Data ---\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \"../cleaned_DS/\"\n",
    "\n",
    "# Create the output directory if it doesn't already exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate the new filename\n",
    "filename_without_ext = get_filename_without_ext(file_dir)\n",
    "output_path = f\"{output_dir}{filename_without_ext}_cleaned.csv\"\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV, without the pandas index\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully cleaned and saved data to: {output_path}\")\n",
    "print(f\"Total processed emails: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c88c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
